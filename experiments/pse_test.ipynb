{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# PSE (PatternStreamEncoder) Test Notebook\n", "\n", "Bu notebook PSE'nin performansını test eder:\n", "- Veri yükleme ve hazırlık\n", "- PSE output hesaplama\n", "- Entropy profili görselleştirme\n", "- Hız karşılaştırması (PSE vs BPE)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 1. Import'lar ve Setup\n", "import torch\n", "import torch.nn.functional as F\n", "import matplotlib.pyplot as plt\n", "import time\n", "from transformers import GPT2TokenizerFast\n", "from src.pse import PatternStreamEncoder\n", "\n", "print(f\"PyTorch version: {torch.__version__}\")\n", "print(f\"CUDA available: {torch.cuda.is_available()}\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 2. PSE Instance Oluşturma\n", "pse = PatternStreamEncoder(window_size=128)\n", "\n", "# CUDA kullanılabilirse GPU'ya taşı\n", "if torch.cuda.is_available():\n", "    pse = pse.cuda()\n", "    print(\"PSE GPU'ya taşındı\")\n", "else:\n", "    print(\"PSE CPU'da çalışıyor\")\n", "\n", "print(f\"PSE parameters: {sum(p.numel() for p in pse.parameters())} parameters\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 3. Veri Yükleme\n", "print(\"Veri yükleme...\")\n", "with open(\"data/raw/wikitext_sample.txt\", \"r\", encoding=\"utf-8\") as f:\n", "    full_text = f.read()\n", "\n", "# İlk 50k karakteri al\n", "text = full_text[:50000]\n", "print(f\"Toplam dosya boyutu: {len(full_text)} karakter\")\n", "print(f\"Test için kullanılan: {len(text)} karakter\")\n", "print(f\"İlk 100 karakter: {text[:100]}...\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 4. PSE Output Hesaplama\n", "print(\"\\n=== PSE OUTPUT HESAPLAMA ===\")\n", "\n", "start_time = time.time()\n", "stream = pse(text)\n", "pse_time = time.time() - start_time\n", "\n", "print(f\"Input length: {len(text)} chars\")\n", "print(f\"Stream shape: {stream.shape}\")\n", "print(f\"Effective compression: {stream.shape[0] / len(text):.4f} windows/char\")\n", "print(f\"PSE processing time: {pse_time:.4f}s\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 5. Entropy Profili Görselleştirme\n", "print(\"\\n=== ENTROPY PROFİLİ HESAPLAMA ===\")\n", "\n", "device = next(pse.parameters()).device\n", "entropy_profile = pse._compute_entropy_profile(torch.tensor([ord(c) for c in text], device=device))\n", "\n", "print(f\"Entropy profile shape: {entropy_profile.shape}\")\n", "print(f\"Mean entropy: {entropy_profile.mean().item():.4f}\")\n", "print(f\"Std entropy: {entropy_profile.std().item():.4f}\")\n", "\n", "# Görselleştirme\n", "plt.figure(figsize=(12, 4))\n", "plt.plot(entropy_profile.cpu().numpy())\n", "plt.title(\"Entropy Profile - Pattern Detection\")\n", "plt.xlabel(\"Window Position\")\n", "plt.ylabel(\"Entropy Value\")\n", "plt.grid(True, alpha=0.3)\n", "plt.tight_layout()\n", "\n", "# Experiments klasörüne kaydet\n", "plt.savefig(\"experiments/entropy_profile.png\", dpi=150, bbox_inches='tight')\n", "print(\"Entropy profili kaydedildi: experiments/entropy_profile.png\")\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 6. Hız Karşılaştırması: BPE vs PSE\n", "print(\"\\n=== HIZ KARŞILAŞTIRMASI ===\")\n", "\n", "# BPE Tokenizer\n", "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n", "\n", "# BPE test\n", "start = time.time()\n", "bpe_tokens = tokenizer.encode(text)\n", "bpe_time = time.time() - start\n", "\n", "# PSE test (tekrar ama daha hassas timing)\n", "start = time.time()\n", "pse_output = pse(text)\n", "pse_time_new = time.time() - start\n", "\n", "print(f\"BPE time: {bpe_time:.4f}s\")\n", "print(f\"PSE time: {pse_time_new:.4f}s\")\n", "print(f\"Speedup: {bpe_time/pse_time_new:.2f}x\")\n", "print(f\"BPE tokens: {len(bpe_tokens)}\")\n", "print(f\"PSE windows: {pse_output.shape[0]}\")\n", "\n", "# Hız analizi\n", "if bpe_time / pse_time_new >= 1.2:\n", "    print(\"✅ PSE BPE'den hızlı!\")\n", "else:\n", "    print(\"❌ PSE yavaş, window_size optimizasyonu gerekli\")\n", "    print(\"Window size 256 ile tekrar denenmeli.\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 7. Window Size 256 ile Optimizasyon Testi\n", "print(\"\\n=== WINDOW SIZE 256 OPTİMİZASYONU ===\")\n", "\n", "# PSE256 oluştur\n", "pse_256 = PatternStreamEncoder(window_size=256)\n", "if torch.cuda.is_available():\n", "    pse_256 = pse_256.cuda()\n", "\n", "# Test\n", "start = time.time()\n", "stream_256 = pse_256(text)\n", "pse_256_time = time.time() - start\n", "\n", "print(f\"PSE-128 time: {pse_time_new:.4f}s\")\n", "print(f\"PSE-256 time: {pse_256_time:.4f}s\")\n", "print(f\"PSE-128 compression: {stream.shape[0] / len(text):.4f} windows/char\")\n", "print(f\"PSE-256 compression: {stream_256.shape[0] / len(text):.4f} windows/char\")\n", "print(f\"PSE-256 vs BPE speedup: {bpe_time / pse_256_time:.2f}x\")\n", "\n", "if bpe_time / pse_256_time >= 1.2:\n", "    print(\"✅ PSE-256 BPE'den hızlı!\")\nelse:\n", "    print(\"❌ PSE-256 de yavaş.\")\n", "\n", "print(f\"\\n=== SONUÇ ÖZETİ ===\")\n", "print(f\"Veri boyutu: {len(text)} karakter\")\n", "print(f\"BPE tokenization: {bpe_time:.4f}s\")\n", "print(f\"PSE-128: {pse_time_new:.4f}s (speedup: {bpe_time/pse_time_new:.2f}x)\")\n", "print(f\"PSE-256: {pse_256_time:.4f}s (speedup: {bpe_time/pse_256_time:.2f}x)\")\n", "print(f\"Entropy profile kaydedildi: experiments/entropy_profile.png\")"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.10"}}, "nbformat": 4, "nbformat_minor": 4}
